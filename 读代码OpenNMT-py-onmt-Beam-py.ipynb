{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 类Beam(object):\n",
    "### 变量\n",
    "- size: = beamSize\n",
    "- done: 默认false 用处目前不明 ？？？？\n",
    "- tt: = torch.cuda if cuda else torch\n",
    "- scores: beam中各个翻译的分数 初始化为self.tt.FloatTensor(size).zero_()\n",
    "- allScores: 列表类 用处目前不明 ？？？？\n",
    "- prevKs: 列表类 记录各个时间点的prevK。prevK指明了当前单词是来自哪个beam\n",
    "- nextYs: 各个时间节点的输出 初始化为[self.tt.LongTensor(size).fill_(onmt.Constants.PAD)]，nextYs[0][0] = onmt.Constants.BOS。初始只有一项\n",
    "- attn: 列表类，记录各个时间节点上的attention\n",
    "\n",
    "### 方法\n",
    "##### __init__(self, size, cuda = False):\n",
    "- size是beamSize\n",
    "- 主要是对变量进行初始化\n",
    "\n",
    "##### getCurrentState(self):\n",
    "- 获得当前时间节点的输出\n",
    "- out size: beam_size\n",
    "- return self.nextYs[-1]\n",
    "\n",
    "##### getCurrentOrigin(self):\n",
    "- 获得当前时间节点的backpointer\n",
    "- out size: beam_size\n",
    "- return self.prevKs[-1]\n",
    "\n",
    "##### advance(self, wordLK, attnOut):\n",
    "- 两个参数:\n",
    "    - wordLk: (beamSize, tgt_dict.size)\n",
    "    - attn: (beamSize, seq_len)\n",
    "- 返回：True if beam search is complete\n",
    "- 主要实现，把generator得到的分数和历史分数进行整合，选择合适的单词，作为各个beam的当前的候选单词。并记录起来。\n",
    "- 后面还是看代码把："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def advance(self, wordLk, attnOut):\n",
    "    # 这里就先当numWords时tgt_dict.size了\n",
    "    numWords = wordLk.size(1)\n",
    "    \n",
    "    # prevKs不知道是什么鬼？？？\n",
    "    if len(self.prevKs) > 0:\n",
    "        # score是[beam]的，保存着上一轮每个beam的得分。加上历史得分，从而得到目前为止总的分数\n",
    "        beamLk = wordLk + self.scores.unsqueeze(1).expand_as(wordLk)\n",
    "    else:\n",
    "        beamLk = wordLk[0]\n",
    "    \n",
    "    # flat后进行排序是为了从整体中得到最优的点。假如我们从各个beam的候选单词中各自选出一个对应最优分数的单词，那么也就是说，一旦确定了，\n",
    "    # 这个选择是不能改变的。后来者都会用到这个选择。就像贪婪算法，这并不能得到全局最优。flat后的方法，虽然也不能得到全局最优，\n",
    "    # 但至少，它多了(beamSize-1)*numWords个选择,\n",
    "    # 举个例子，字母表是a, b, c。 beamSize是2.首轮a, b分数最高分别是3，1。第二轮得到的a, b, c的得分分别为1, 2, 1.\n",
    "    # 那么扩展相加后的得分是:[[4, 5, 4], [2, 3, 2]]。\n",
    "    # 如果按照每个beam选一个那么这里会选的是1b,2b。即得到的句子为ab(4), bb(3)\n",
    "    # 如果按照flat后进行选择，则这里选的会是1a,1b。即得到的句子为aa(4), ab(5)\n",
    "    # 可以明显看到第二种方法的结果更优。这所以说这里不是全局最优，如上面可以看到，第二轮的选择上，已经不再注意首轮选c的情况了。\n",
    "    flatBeamLk = beamLk.view(-1)\n",
    "    bestScores, bestScoresId = flatBeamLk.topk(self.size, 0, True, True)\n",
    "    self.allScores.appen(self.scores)\n",
    "    self.scores = bestScores\n",
    "    \n",
    "    # bestScoresId is flattended beam X word array, so calculate which\n",
    "    # word and beam each score came from \n",
    "    # 正如相面说的topk是从flat后的数据中选择的，这里我们想具体的知道，这个被选中的家伙是从哪个beam中被选出来的。从而可以把他添加到对应\n",
    "    # 的历史数据中。\n",
    "    # 下面这个语句，可以看出这个单词是来自哪个beam\n",
    "    prevK = bestScoresId /numWords\n",
    "    self.prevKs.append(prevK)\n",
    "    self.nextYs.append(bestScoresId - prevK * numWords)\n",
    "    # 记录attn\n",
    "    self.attn.append(attnOut.index_select(0, prevK))\n",
    "    \n",
    "    # End condition is when top-of-beam is EOS\n",
    "    if self.nextYs[-1][0] == onmt.Constants.EOS:\n",
    "        self.done = True\n",
    "        self.allScores.append(self.scores)\n",
    "    \n",
    "    return self.done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sortBest(self):\n",
    "- return torch.sort(self.scores, 0, True)\n",
    "\n",
    "##### getBest(self):\n",
    "- get the score of the best in the beam\n",
    "\n",
    "##### getHyp(self, k):\n",
    "- 获得beamSize个预测的分数最高的句子\n",
    "- prevK指向了当前单词使用的历史对象，而他又可以从上一个事件点的nextY中直接提取出来，所以从后往前依次提取出来就是了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBest(self):\n",
    "    hyp, attn = [], []\n",
    "    for j in range(len(self.prevKs) - 1, -1, -1):\n",
    "        hyp.append(self.nextYs[j + 1][k])\n",
    "        attn.append(self.attn[j][k])\n",
    "        k = self.prevKs[j][k]\n",
    "    \n",
    "    return hyp[::-1], torch.stack(attn[::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2-tf",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
